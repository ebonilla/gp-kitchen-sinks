%%%%%%%%%
\subsection{Large Scale Classification} 
Here we present the results of our inference algorithm on a larger application on the 
\mnist dataset, which contains examples of handwritten digits, 50,000 for training, 10,000 
for validation and 10,000 for testing. In our experiments below, we always train on 60,000 
examples that include the training and the validation set and tune the parameters of our 
models via optimization of the variational bound. This is probably a disadvantage when compare
to other approaches that use cross-validation but our goals is to show that our models can 
achieve competitive performance at this scale. 

We first consider the binary classification problem of distinguishing the odd digits vs the 
even digits, a task that has also been investigated by \cite{hensman-et-al-aistats-2015}.
The results are shown in Table \ref{tab:mnist-binary}, for our methods (\eks and \uks) and 
the methods by  \citep[][\hmg]{hensman-et-al-aistats-2015} and \citep[][\dnb]{dezfouli-bonilla-nips-2015}.
As before, we report the mean negative log probability and the error rate on the test 
set for different number of feature basis. We see that our methods achieve similar performance 
to \hmg and \dnb when using 2000 feature basis, while \dnb is an inducing-point approach that 
fixes  inducing points (2000)

Table \ref{fig:mnistBinary}
Here we show the results on \mnist dataset.
\begin{table}[h]
\caption{The performance of the models on the \mnist dataset for the 
task of classifying the even digits vs the odd digits.
\label{fig:mnistBinary}
}
\begin{tabular}{c c c c c}
\toprule
& \multicolumn{2}{c}{NLP} & \multicolumn{2}{c}{Error Rate} \\
& D = 1000 & D = 2000 & D = 1000 & D = 2000 \\
\midrule
\eks &  0.129 & 0.088 & 0.043 & 0.026 \\
\uks &  0.129 & 0.088 & 0.043 & 0.026 \\
\hmg &      \multicolumn{2}{c}{0.069}    &            \multicolumn{2}{c}{0.022}   \\
\dnb   &      \multicolumn{2}{c}{0.068}    &            \multicolumn{2}{c}{0.022}\\
\bottomrule
\end{tabular}
\end{table}

\hmg refers to \citet{hensman-et-al-aistats-2015} 
\dnb refers to \citet{dezfouli-bonilla-nips-2015}




